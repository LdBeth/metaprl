%
% Simple documentation for the refiner.
%

\documentclass{article}

\setlength{\topmargin}{-1.0 in}
\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\textwidth}{6.0 in}
\setlength{\textheight}{9.5 in}

\newcommand\Nuprl{{\it Nuprl}}
\newcommand\NuprlLight{NuprlLight}
\newcommand\metarightarrow{\longrightarrow}
\newcommand\ttmetarightarrow{\mathrel{\hbox{\tt -->}}}
\newcommand\metaleftrightarrow{\longleftrightarrow}
\newcommand\ttmetaleftrightarrow{\mathrel{\hbox{\tt <-->}}}

\newcommand\nequal{\neq}
\newcommand\syntax{\noindent{\bf Syntax}\makebox[1in]{\dotfill}\rule[-1em]{0em}{3em}\par\noindent}
\newcommand\mlsemantics{\noindent{\bf ML Definitions}\makebox[1in]{\dotfill}\rule[-1em]{0em}{3em}\par\noindent}

\begin{document}

%\setlength{\baselineskip}{24pt}

\title{\NuprlLight{} User Guide}
\author{Jason Hickey}
\date{\today}

\maketitle

\section{Introduction}

\NuprlLight{} is intended to be similar to an ML-style programming language with additional
constructs for defining logics (including constructive type theory), and facilities for proving
properties about objects in the logics.  \NuprlLight{} is really a logical framework with primitives
for defining:
\begin{itemize}
\item
  Computational rewrites
\item
  Inference rules
\end{itemize}
These primitives are intermixed with normal ML program constructs, and \NuprlLight{} provides
tools for composing rewrites and rules into ML programs that provide more complex reasoning and
refinements.

All objects in Nuprl are expressed as objects of ML type {\tt term}, which has a uniform interface
definition, and is an abstract type in the implementation.  Computational rewrites are expressed as 
relations on terms, as are inference rules.

% A logic is defined in \NuprlLight{} by creating a {\em module}, which has a {\em signature\/} and
% possibly an implementation.  Within the module, rewrite rules are added to the system to define
% computation in the logic, and inference rules of the logic are stated.  For instance, in the
% standard \Nuprl{} type theory, beta reduction is defined to provide an untyped $\lambda$-calculus,
% then the rules of the type theory are listed.

In \NuprlLight{}, all definitions are through the module system.  Modules are {\em theories\/} of
the logic, and they have signatures, which consist of the types of the axioms.  The {\em
  implementations\/} of the module contain {\em theorems\/} for each of the axioms.  Axioms play the
part of assumptions in the theory, and additional components of the theory may assume that the
axioms are true and inhabited by some proof object.  Theorems are statements that follow from the
rules of the theory and any axioms that have been assumed up to the point when the theorem is
proved.

A major goal in our construction is to implement a module system that incorporates concepts from
object-oriented programming as well as the higher order module systems for languages like Standard
ML.  For our purposes, a module is defined as a collection of formal objects. In the following
sections we describe some of those objects. The object-oriented thrust of the module system is to
provide module extension and inheritance, while the SML thrust is to provide signatures for modules
and higher order functors.

In addition to formal object, theories may contain objects like tactics, which are ML code that embody reasoning 
in the theory.  Proofs using tactics are always reducible to a primitive rule tree where each node 
corresponds to a primitive inference of the logic.  Theories can also contain other informal objects, like
display forms (which specify how to print terms), comments, or other information.

In the following sections, we cover the parts of the system in more detail.  In some cases this
includes information about the implementation.  In other cases, the issues have not been
implemented, and are proposals for the system.

\section{Overview}

As stated in the introduction, all definitions in \NuprlLight{} occur in modules.  The current
module system in \NuprlLight{} is organized around the filesystem.  Module {\em signatures\/} are
defined in a file with the name {\it module}{\tt .prli}, and the initial implementation of the
module is defined in a corresponding file {\it module}{\tt .prl}.  The current implementation of
\NuprlLight{} is specific to the Caml-Light programming language, and the {\tt .prli} and {\tt .prl}
files are compiled into {\tt .mli} and {\tt .ml} files respectively.

Within a module file, ML code can be arbitrarily intermixed with \NuprlLight{} statements, with the
general restriction the \NuprlLight{} statements must occur at the top level.  The exception to this
is for {\em terms}, which may occur at any point in the file.  The {\tt .prli} and {\tt .prl} files are compiled
using the {\tt prlcomp} program, which is described in Section~\ref{section:prlcomp}.

\section{Terms}

\label{section:terms}
Conceptually, everything in \NuprlLight{} is a term.  All operations in the system are defined on
terms, all formal programs are terms, and all statements in the system are terms.  Terms are
implemented in the file {\tt term.ml} and they have the following uniform syntax:

\begin{center}
  {\tt\begin{tabular}{lll}
      term & ::= & operator(bterm list)\\
      operator & ::= & opname{params}\\
      opname & ::= & string\\
      params & ::= & param list\\
      param & ::= & int \hbox{:} n | string \hbox{:} s | string \hbox{:} t |\\
            &     & string \hbox{:} v | level \hbox{:} l | meta-param\\
      level & ::= & number | var | level number | level' | level "|" level\\
      bterm & ::= & string list . term
    \end{tabular}}
\end{center}

In this table, we use informal type notation.  For instance, the operator name is specified as a
list of strings, but the exact syntax is left unspecified.

Each term has an operator, which contains a name and a list of parameters. The parameters are used
to encode operators more efficiently.  For instance, the natural numbers 0, 1, ... can be given the
encoding ${\tt natural\_number}\{0\}$, ${\tt natural\_number}\{1\}$, $\ldots$, to expose the number
of a parameter, rather than incorporating the number into the operator name.

Each term contains a list of subterms, each of which has some (possibly empty) binding context.  For
instance, a standard $\lambda$-abstraction can be encoded in the form ${\tt lambda}\{\}(x.b)$, where
$x$ is bound in $b$.  More complex binding structure can be used if desired, but in each case, the
binding variables are limited to range over a single subterm.  The equality on terms respects
renaming of bound variables.

\subsection{Special terms}

The following terms are special to the system.
\begin{center}
  \begin{tabular}{ll}
    ${\tt var}\{n:v\}()$ & first order variable with name $n$\\
    ${\tt var}\{n:v\}({\it terms})$ & second order variable; the {\it terms} are simple\\
    ${\tt context}\{n:v\}({\it hole}; {\it terms})$ & a context with a single hole\\
  \end{tabular}
\end{center}
First order variables have the standard meaning.  Second order variables are used to provide
a form of second order abstraction.  For instance, a rewrite for beta equality might be defined as
follows:
$${\tt apply}({\tt lambda}(x. b[x]); a) \metaleftrightarrow b[a]$$
where we use the notation $b[x]$ for the second order variable ${\tt var}\{b:v\}({\tt
  var}\{x:v\}())$.  This rule specifies a collection of rewrites: one for each term $b$ having a free
variable $x$, where $b[a]$ specifies $b$ with $a$ substituted for $x$.

Context have a similar meaning, and are used to specify inference rules.  They will be described in
Section~\ref{section:implementation}, and they are not used at the top level.

\subsection{Term syntax}

\NuprlLight{} contains a simple parser for terms that are embedded in input files.  Terms may occur
at any point in the file, and are delimited by the pairs ({\tt termbegin}, {\tt end}), or ({\tt (|},
{\tt |)}).  Tables~\ref{table:syntax1} and \ref{table:syntax2} describe the general syntax for terms:

\begin{table}[ht]
\begin{center}
  {\tt \begin{tabular}{|rcll|}
      \hline
      \multicolumn{3}{|l|}{Production} & Description\\
      \hline\hline
      {\it term} & {\rm ::=} & {\it singleterm} & $\$1$\\
           & $|$ & {\it singleterm}\ {\it singleterm} & ${\tt apply}(\$1; \$2)$\\
           & $|$ & - {\it term} & ${\tt neg}(\$1)$\\
           & $|$ & ${\it term}_1$ + ${\it term}_2$ & ${\tt add}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ - ${\it term}_2$ & ${\tt sub}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ * ${\it term}_2$ & ${\tt mul}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ / ${\it term}_2$ & ${\tt div}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ \% ${\it term}_2$ & ${\tt rem}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ > ${\it term}_2$ & ${\tt gt}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ >= ${\it term}_2$ & ${\tt ge}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ <= ${\it term}_2$ & ${\tt le}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ < ${\it term}_2$ & ${\tt lt}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ = ${\it term}_2$ in ${\it term}_3$ &
              ${\tt equal}({\it term}_3; {\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ <> ${\it term}_2$ in ${\it term}_3$ &
              ${\tt nequal}({\it term}_3; {\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ \hbox{::} ${\it term}_2$ &
              ${\tt cons}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ $/\backslash$ ${\it term}_2$ &
              ${\tt and}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ \& ${\it term}_2$ &
              ${\tt and}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ $\backslash/$ ${\it term}_2$ &
              ${\tt or}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ => ${\it term}_2$ &
              ${\tt implies}({\it term}_1; {\it term}_2)$\\
           & $|$ & ${\it term}_1$ -> ${\it term}_2$ &
              ${\tt fun}({\it term}_1; {\it term}_2)$\\
           & $|$ & $v$ \hbox{:} ${\it term}_1$ -> ${\it term}_2$ &
              ${\tt fun}({\it term}_1; v. {\it term}_2)$\\
           & $|$ & all $v$ \hbox{:} ${\it term}_1$ . ${\it term}_2$ &
              ${\tt all}({\it term}_1; v. {\it term}_2)$\\
           & $|$ & isect $v$ \hbox{:} ${\it term}_1$ . ${\it term}_2$ &
              ${\tt intersection}({\it term}_1; v. {\it term}_2)$\\
           & $|$ & ${\it term}_1$ \# ${\it term}_2$ &
              ${\tt prod}({\it term}_1; {\it term}_2)$\\
           & $|$ & $v$ \hbox{:} ${\it term}_1$ \# ${\it term}_2$ &
              ${\tt prod}({\it term}_1; v. {\it term}_2)$\\
           & $|$ & exists $v$ \hbox{:} ${\it term}_1$ . ${\it term}_2$ &
              ${\tt exists}({\it term}_1; v. {\it term}_2)$\\
           & $|$ & ${\it term}_1$ | ${\it term}_2$ &
              ${\tt union}({\it term}_1; {\it term}_2)$\\
           & $|$ & $\{$ $v$ \hbox{:} ${\it term}_1$ $|$ ${\it term}_2$ $\}$ &
              ${\tt set}({\it term_1}; v. {\it term}_2)$\\
           & $|$ & $\{$ $f$ $|$ $v$ \hbox{:} ${\it term}_1$ -> ${\it term}_2$ $\}$ &
              ${\tt rfun}({\it term}_1; f, v. {\it term}_2)$\\
           & $|$ & quot $v_1$, $v_2$ \hbox{:} ${\it term}_1$ // ${\it term}_2$ &
              ${\tt quotient}({\it term}_1; x, y. {\it term}_2)$\\
           &&&\\
      {\it terms} & {\rm ::=} & \multicolumn{2}{l|}{{\it term} $|$ {\it terms} ; {\it term}}\\
      \hline
    \end{tabular}}
\end{center}
\caption{\label{table:syntax1}Syntax: Part 1}
\end{table}

\begin{table}[ht]
\begin{center}
  {\tt \begin{tabular}{|rcll|}
      \hline
      \multicolumn{3}{|l|}{Production} & Description\\
      \hline\hline
      {\it singleterm} & {\rm ::=} & $\left<{\it string} \right>$ ${\it optparams}$ ${\it optbterms}$ &
         ${\it string} \{ {\it params} \} ( {\it bterms} )$\\
                 & $|$ & ' $\left<{\it string}\right>$ &
                    ${\tt var}\{ \left< {\it string} \right> : v \}$\\
                 & $|$ & ' $\left<{\it string}\right>$ [ ${\it terms}$ ] &
                    ${\tt var} \{ \left<{\it string}\right> : v \}( {\it terms} )$\\
                 & $|$ & $\left<{\it number}\right>$ &
                    ${\tt natural\_number}\{ \left< {\it number} \right> : n \}$\\
                 & $|$ & \multicolumn{2}{l|}{%
                   sequent $\{$
                     $v_1$ \hbox{:} ${\it term}_1$ ; {\it ...} ; $v_n$ \hbox{:} ${\it term}_n$ >>
                     {\it terms} $\}$}\\
                 & & \multicolumn{2}{l|}{%
                        ${\tt hyp}({\it term}_1; v_1. ... {\tt hyp}({\it term}_n; v_n.
                        {\tt concl}({\it terms})))$}\\
                 & $|$ & ( {\it term} ) & {\it term}\\
      &&&\\
      {\it optparams} & {\rm ::=} & \multicolumn{2}{l|}{$\epsilon$ | $\{$ {\it params} $\}$}\\
      {\it params} & {\rm ::=} & \multicolumn{2}{l|}{{\it param} | {\it params} ; {\it param}}\\
      {\it param} & {\rm ::=} & $\left<{\it number}\right>$ \hbox{:} n & {\rm (number)}\\
            & $|$ & $\left<{\it string}\right>$ \hbox{:} s & {\rm (string)}\\
            & $|$ & $\left<{\it string}\right>$ \hbox{:} t & {\rm (token)}\\
            & $|$ & $\left<{\it string}\right>$ \hbox{:} v & {\rm (variable)}\\
            & $|$ & {\it level} \hbox{:} l & {\rm (level expression)}\\
            & $|$ & \$ $\left<{\it string}\right>$ \hbox{:} n & {\rm (meta-number)}\\
            & $|$ & \$ $\left<{\it string}\right>$ \hbox{:} s & {\rm (meta-string)}\\
            & $|$ & \$ $\left<{\it string}\right>$ \hbox{:} t & {\rm (meta-token)}\\
            & $|$ & \$ $\left<{\it string}\right>$ \hbox{:} v & {\rm (meta-variable)}\\
            & $|$ & \$ $\left <{\it string}\right>$ \hbox{:} l & {\rm (meta-level)}\\
            & $|$ & {\it param} + {\it param} & {\rm (param addition)}\\
            & $|$ & {\it param} - {\it param} & {\rm (param subtraction)}\\
            & $|$ & {\it param} * {\it param} & {\rm (param multiplication)}\\
            & $|$ & {\it param} / {\it param} & {\rm (param division)}\\
            & $|$ & {\it param} \% {\it param} & {\rm (param remainder)}\\
      &&&\\
      {\it optbterms} & {\rm ::=} & \multicolumn{2}{l|}{$\epsilon$ | ( {\it bterms} )}\\
      {\it bterms} & {\rm ::=} & \multicolumn{2}{l|}{{\it bterm} | {\it bterms} ; {\it bterm}}\\
      {\it bterm} & {\rm ::=} & {\it term} &\\
            & $|$ & $\left<{\it string}\right>$ , {\it ...} , $\left<{\it string}\right>$ . {\it term} &\\
      \hline
    \end{tabular}}
\end{center}
\caption{\label{table:syntax2}Syntax: Part 2}
\end{table}

\section{Language Constructs}

In a general logical framework, the goal of the theorist is to build a specific logic, and then to
construct models on the logic and show that they meet certain properties as specified in the
logic.  In a constructive setting, there is an additional correspondence between proofs and
computation.  Statements in the logic are the specifications of programs, and the goal is to find
implementations.  With this view in mind, our task in this section is to define a programmatic
interface to the logical framework of \NuprlLight{}.  For the most part, we will not assume the use
of a constructive logic, but some of the features we present will be especially useful for
constructive logics (for example, our handling of proof extracts as programs).

There are many types of objects that are desirable in a module for formal verification.  Some are
formal, and some are not.  We define a formal object to be any object that belongs to a formal type
(which usually includes types as formal objects). Formal objects include most axioms and theorems,
and informal objects include comments, procedures describing how to display or parse terms, tactics,
etc. As we describe the objects of the theory, we will be careful to point out which objects are
formal.

The current implementation of \NuprlLight{} is for Caml-Light, and the constructs we give in the
following sections are extension of the Caml-Light language.  In the descriptions for each
construct, we give the specification for the construct, its informal semantics, and lastly we
describe its corresponding construct in Caml-Light.

\subsection{Term Declarations}

\syntax

$$
\begin{array}{|l|}
\hline
\hbox{\tt declare}\ {\it term}\\
\hbox{\tt define name}\ {\it term}_1 \ttmetaleftrightarrow {\it term}_2\\
\hline
\end{array}
$$

Before a specific term can be used in a module, it must be {\em declared}.  Terms that are not
declared will produce a warning.  The {\tt declare} form specifies a new term that is new to the
module that is currently being defined.

The {\tt define} form specifies that ${\it term}_1$ is defined as ${\it term}_2$.  This is a form of
computational equivalence: in any context, an instance of ${\it term}_1$ can be replaced by an
instance of ${\it term}_2$.  The definition can be specified using {\em second order\/} variables, of the
form $v[x_1, \ldots, x_n]$, where $v$ is a variable, and $x_1, \ldots, x_n$ are terms (including
variables).

Intuitively, the definition specifies a collection of equivalences.
For instance, consider the following definition:

\begin{verbatim}
        define letDefinition : let('e; x. 'b['x]) <--> 'b['e];;
\end{verbatim}

This specifies that for any term $b$ having a free variable $x$, that ${\tt let}(e; x. b[x])$ is
computationally equivalent to $b[e]$.  The term $b$ and variable $x$ specify {\em
  any\/} term and variable; so, for instance, this definition includes the following equivalences:

\begin{eqnarray*}
{\tt let}(1; z. 7 + z) & \equiv & 7 + 1\cr
{\tt let}(lambda(x. x\ x); f. f\ f) & \equiv & lambda(x. x\ x)\ lambda(x. x\ x)
\end{eqnarray*}

The {\tt define} form is equivalent to a {\tt declare} form, following by a {\tt rewrite} definition
(as described in the following section).  The equivalence is as follows:

\begin{center}
  {\tt \begin{tabular}{|l|}
    \hline
    define name : ${\it term}_1$ <--> ${\it term}_2$;;\\
    \multicolumn{1}{|c|}{{\it means}}\\
    declare ${\it term}_1$;;\\
    rewrite name : ${\it term}_1$ <--> ${\it term}_2$;;\\
    \hline
  \end{tabular}}
\end{center}

\mlsemantics
A {\tt declare} form doesn't produce any object, but a {\tt define} form defines a rewrite as
follows:
\begin{verbatim}
        value name : rewrite;;
\end{verbatim}

\subsection{Rewrites}

The next construction is for defining {\em rewrites}, which specify terms that are computationally
equivalent.  The basic form is rewrite is declared with the following construct:

\syntax
$$
\begin{array}{|l|}
\hline
\hbox{\tt rewrite name}\ {\it params} : {\it cond}_1 \ttmetarightarrow \cdots \ttmetarightarrow
  {\it cond}_n \ttmetarightarrow ({\it redex} \ttmetaleftrightarrow {\it contractum});;\\
\hbox{\tt primrw name}\ {\it params} : {\it cond}_1 \ttmetarightarrow \cdots \ttmetarightarrow
  {\it cond}_n \ttmetarightarrow ({\it redex} \ttmetaleftrightarrow {\it contractum});;\\
\hbox{\tt rwthm name}\ {\it params} : {\it cond}_1 \cdots {\it cond}_n\ {\it redex} : {\it contractum} = {\it mlcode};;\\
\hline
\end{array}
$$

A {\tt rewrite} specifies that, in any context, if the {\it conditions\/} hold, then the ${\it redex}$ is
computationally equivalent to the ${\it contractum}$.  The {\it params\/} specify extra parameters
to the rewrite.  The rewrite is specified using {\em second order\/} variables.
For instance, beta reduction is declared as follows:

\begin{verbatim}
        rewrite beta apply(lambda(x. 'b['x]); 'a) <--> 'b['a];;
\end{verbatim}

In this rewrite $b[x]$ is a second order variable that specifies that $x$ is bound in $b$.  The
second order application $b[a]$ specifies $b$ with $a$ substituted for $x$.
Intuitively, the {\tt rewrite} specifies a collection of rewrite rules where $b$ is any term with a
free variable $x$, and $b[a]$ specifies the substitution $b\{x \leftarrow a\}$.
The {\it params\/} are extra parameters to the rewrite.

Rewrites can also be conditional.
For instance, consider the following rewrite:

\begin{verbatim}
        rewrite one : ('i <> 0 in int) --> ('i / 'i <--> 1);;
\end{verbatim}

This rule spcifies that the fraction $i / i$ can be rewritten to 1 if $i$ is nonzero.
Conditional rewrites can only be used in a logic that is specified using a sequent calculus because
the conditions are relative to any assumptions that are in place at the time the rewrite is used.

Rewrites can be implemented in two forms.  A {\em primitive\/} rewrite is specified using the
keyword {\tt primrw}, with the same syntax as a rewrite, and it specifies that the rewrite is valid
in the current logic.

A {\em derived\/} rewrite is specified using the {\tt rwthm\/} form, which specifies that the {\tt
redex} can be rewritten to the {\tt contractum} given the {\tt conditions} and {\tt params} and the
derivation specified in the {\tt mlcode}.

Meta-parameters can be used in rewrites to specify abstract paprameters (meta-parameters are not
useful outside of rewrite rules).  Addition is specified as follows in the Nuprl type
theory:

\begin{verbatim}
  rewrite sum : natural_number{$i:n} + natural_number{$j:n}
     <--> natural_number{$i + $j};;
\end{verbatim}
The meta-parameters $\$i$ and $\$j$ are abstractions over the parameter values.

\mlsemantics
When a rewrite is declared, one of two ML forms are created.  A simple rewrite has the form
$$\hbox{\tt rewrite name}\ : {\it redex} \ttmetaleftrightarrow {\it contractum};;$$
withouth any conditions or parameters.  A rewrite of this form defines the following ML term:

\begin{verbatim}
        value name : rewrite;;
\end{verbatim}

A conditional rewrite has the general form.  The parameters to a conditional rewrite specify one of
two types of information:
\begin{enumerate}
\item
  Variable names
\item
  Term arguments
\end{enumerate}
For instance, a reverse beta-reduction might be specified using a term argument:

\begin{verbatim}
        rewrite rev_beta lambda(x. 'b['x]) : 'b['a] <--> (lambda(x. 'b['x]) 'a);;
\end{verbatim}

The extra parameter is necessary for applying the rewrite, and the ML declaration has the form:

\begin{verbatim}
        value rev_beta \hbox{:} term -> cond_rewrite;;
\end{verbatim}

Similarly, parameters that specify variable names become string arguments to the rewrite.

\subsection{Refinements}

Refinments include {\em axioms}, which are statements that are assumed to be valid, and proofs of
axioms, either primitive or derived.  The construct for delcaring these logical statements are as follows:

\syntax
$$
\begin{array}{|l|}
  \hline
  \hbox{\tt axiom name}\ {\it param}_1\ \cdots\ {\it param}_n\ \hbox{\tt :}\
    {\it subgoal}_1 \ttmetarightarrow \cdots \ttmetarightarrow {\it subgoal}_m \ttmetarightarrow
    {\it goal}{\tt ;;}\\

  \hbox{\tt prim name}\ {\it param}_1\ \cdots\ {\it param}_n\ \hbox{\tt :}\
    v_1\colon {\it subgoal}_1 \ttmetarightarrow \cdots \ttmetarightarrow v_m\colon {\it subgoal}_m
    \ttmetarightarrow {\it goal}{\tt ;;}\\

  \hbox{\tt thm name}\ {\it param}_1\ \cdots\ {\it param}_n\ \hbox{\tt :}\ {\it subgoal}_1 \cdots
    {\it subgoal}_m\ \hbox{\tt :}\ {\it goal} = {\tt mlbegin}\ {\it mlcode}\ {\tt mlend;;}\\
  \hline
\end{array}
$$

An {\tt axiom} specifies a statement that is assumed to be true in the current logic.  This
statement may be used in a signature, or in an implementation of a module.  The $\ttmetarightarrow$
symbol can be read as an implication: if the subgoals are provable, then the goal is provable.  If
there are no subgoals, then the goal is always true.  If there are subgoals, the axiom is called a
{\em rule}.

When the axiom is declared, it defines a new term in the current module
$${\tt name}({\it param}_1; \ldots; {\it param}_n)$$
that stands for the program corresponding to the proof of the axiom.

Axiom can have two forms of implementations (also called justifications).  A primitive theorem is
defined using the {\tt prim} form, which requires a proof extract to be defined for the primitive
rule.  In this case, the subgoals are provided as a list of bound terms, where $v_1, \ldots, v_m$
are second order variables that stand for the proof extracts of each of the subgoals.  The subgoal
specification $\colon {\it subgoal}_i$ is optional.  If it is not provided, the declaration form is
used; it is an error if there is no previous declaration.  The variable ``\_'' is a wildcard
variable.  A {\tt prim} form can occur only in an implementation of a module.

A derived theorem is defined using the {\tt thm} form, and is proved using backward chaining.  The
{\it mlcode\/} specifies a {\em tactic\/} that derives the subgoals from the goal.  The parameters
are used by the resulting derived rule; they are not used within the tactic used in the derivation.
A {\tt thm} form can occur only in the implmentation of a module.

\mlsemantics
An axiom declaration builds a {\tt tactic}.  The parameters of an axiom have one of three types:
\begin{enumerate}
\item
  Context variable address,
\item
  Variable name
\item
  Term argument
\end{enumerate}
For instance, consider the following axiom declaration, taken from the file {\tt itt\_int.prli}.

\begin{verbatim}
  axiom intElimination 'H 'J 'n 'm 'v 'z :
    sequent { 'H; n. int; 'J['n]; m. int; v. 'm < 0; z. 'C['m + 1] >> 'C['m] } -->
    sequent { 'H; n. int; 'J['n] >> 'C[0] } -->
    sequent { 'H; n. int; 'J['n]; m. int; v. 0 < 'm; z. 'C['m - 1] >> 'C['m] } -->
    sequent { 'H; n. int; 'J['n] >> 'C['n] };;
\end{verbatim}

Sequents are described in more detail in Section~\ref{section:sequents}.

This axiom specifies integer induction for intuitionistic type theory.  All statements in the type
theory are {\em sequents}, and the rule specifies these sequents using second order variables and
contexts.  The hypotheses {\tt 'H} and {\tt 'J['n]} specify {\em contexts}, and the parameters {\tt
  'H} and {\tt 'J} specify the addresses of the hole within the corresponding contexts.  The {\tt
  'H} parameter is the hole that contains the hypothesis

\begin{verbatim}
        n. int
\end{verbatim}

and the {\tt 'J} address is the address of the conclusion relative to the context {\tt 'J}.  The
other parameters, {\tt 'n}, {\tt 'm}, {\tt 'v}, and {\tt 'z}, specify the variable names that are to
be used during refinement.

When this axiom is compiled to ML, it is declared as follows:

\begin{verbatim}
        value intElimination : int -> int
            -> string -> string -> string -> string
            -> tactic;;
\end{verbatim}

This {\tt tactic} can be applied to a goal having the desribed form, and it will refine it to
specified subgoals.

The other forms, {\tt prim} and {\tt thm}, do not produce any ML definition.

\subsection{Module inheritance}

In additional to the declaration forms, each theory must declare its parents in its signature with
the {\tt include} form.

\syntax

\begin{center}
  \begin{tabular}{|l|}
    \hline
    \hbox{\tt include}\ {\it module-name}\\
    \hline
  \end{tabular}
\end{center}

This specifies that the module with given name is a {\em parent\/} of the current module.  That
module is explicitely opened, and all the names that are defined in the parent are available in tge
current module.

More than one module can be inherited by using more than one {\tt include} command.  If two module
declare an object with the same name, the last object included will be the default value.
Alternatively, object can be refered to using qualified names.  For ML objects in Caml-Light, a full
name has the form:

$${\it module}{\tt \_\_}{\it name}$$

In Caml Special Light, qualified names have the form:
$$
{\it module}_1 . {\it module}_2 .\ \ldots\ . {\it module}_n . {\it name}
$$

The names of formal objects have a similar naming structure.  Operator names can be qualified with
the form:
$$
{\it module}_1 . {\it module}_2 .\ \ldots\ . {\it module}_n . {\it opname}
$$
Each module must be declared in the previous module, and the {\it opname\/} must refer to a
declared term in the final module.

\section{PRL Compiler}
\label{section:prlcomp}

The {\tt prlcomp} utility compiles {\tt .prli} and {\tt .prl} files into {\tt .mli} and {\tt .ml}
files respectively.  The usage is as follows:

\begin{verbatim}
        prlcomp [-I dir]* <file>.prli
        prlcomp [-I dir]* <file>.prl
\end{verbatim}

The compiler expands terms and commands in the {\tt .prl*} file, and it checks the contructions for
more obvious errors.  Proofs are {\em not\/} expanded.  The compilation of a {\tt .prli} file also
creates a binary {\tt .zsi} file that summarizes the module signature.  This file must exist before
the corresponding {\tt .prl} file is compiled.

The {\tt [-I dir]} options specify directories to search for modules.

\section{Implementation}
\label{section:implementation}

The current implementation of terms uses a datatype that is very similar to the unirofm sytax, and
substitution is performed explicitly (and every substitution copies the entire term).  Here are
some suggestions for making the implementation more efficient.

\begin{enumerate}
\item
Implement Terms as closures, to delay substitution until necessary.
\item
Possibly use DeBruijn terms.  Its not actually clear if this would make the system more 
efficient, since some operations, like subterm projection, become more expensive.
\end{enumerate}

\subsection{Rewrite}

The rewriter provides the main functionality of the refiner.  It is defined in the file {\tt
  rewrite.csl}.  A rewrite is specified using terms containing second order variables and contexts,
  and the rewriter requires that the specification be compiled to a rewrite (of type {\tt
  rewrite}).  This rewrite can then be applied to a redex to rewrite it into a contractum.  An
  error is raised if the redex does not have the correct form.

\subsection{Refinement}

In \NuprlLight{}, refinement is just a relation on terms, which are assigned some meaning in the 
logic.  In most logics, statements have the form of sequents, and refinement is stated using inference 
rules, which are both described in the following two sections. In \NuprlLight{}, both sequents and 
inference rules will be forms of implications and rewrites.

\subsection{Sequents}

\label{section:sequents}
Logical statements in \Nuprl{} are often stated as {\em Sequents}, which are a form of simplified
form of implication.  Sequents are have two collections of terms: the hypotheses specify the
assumptions of the statement, and the conclusions specify possible outcomes. The hypothesed are
separated from the conclusions by a $\vdash$, and each hypothesis is accompanied by a name for the
proof content of the hypotheses.

In general, proofs can have compiled proof forms, called {\em extracts}. In constructive logics, the 
extract is the computational content of a proof.  In a classical logic, the extract may always 
be trivial, or it may contain information about how the proof was performed.  Constructive logics may 
also enforce just a single conclusion in all inferences.

As an example, the following sequent specifies that $C_1, \ldots, C_m$ are possible outcomes from
$x_1\colon H_1, \ldots, x_n\colon H_n$.  In the hypotheses, the proof variables $x_1, \ldots, x_n$
are bound in the conclusions and in following hypotheses.  For instance, $x_1$ is bound in $H_2,
\ldots, H_n$, and $C_1, \ldots, C_m$.

$$x_1\colon H_1, \ldots, x_n\colon H_n \vdash C_1, \ldots, C_m$$

The {\tt term} for a Sequent is defined as follows:

$${\tt hyp}(H_1; x_1. \ldots {\tt hyp}(H_n; x_n. {\tt concl}(C_1; \ldots, {\tt concl}(C_m, {\tt
  concl}()))))$$

This system doesn't assign a particular meaning to a Sequent, but the meaning is often as follows:
$x_1\colon H_1, \ldots, x_n\colon H_n \vdash C_1, \ldots, C_m$ is true iff, assuming each hypothesis
is well-formed and true given that the hypotheses it depends on are also true and well-formed, then
one of the conclusions is true.

\subsection{Inference Rules}

Inference rules specify the inferences that define the logic.  They have the following form:

$$
\begin{array}{rcl}
G & {\tt ext} t[x_1, \ldots, x_n]\\
\multicolumn{3}{l}{{\tt by} {\it params}}\\
S_1 & {\tt ext} & x_1\\
& \vdots &\\
S_n & {\tt ext} & x_n
\end{array}
$$

The $G$ is the goal sequent, and $S_1, \ldots, S_n$ are subgoal sequents.  The extract is computed
by the following rule: if $x_1, \ldots, x_n$ are the proof extracts of $S_1, \ldots, S_n$, then the
extract of $G$ is $t[x_1, \ldots, x_n]$.  The proof extract of a sequent is a function that computes
the proof extract of the conclusion from the proof extracts of the hypotheses.

The rule itself is a function on Sequents: given a goal $G$, it computes subgoals $S_1, \ldots, S_n$
given the parameters in ``params.'' The standard specification of a rule is in the form above, using
second order variables to describe a collection of rules. The application of a rule to a goal is
called a refinement, because it is intended to refine the goal into smaller (and easier to prove)
subgoals.

In the implementation, rules of the above form may also provide side-conditions, which are functions
that take the goal sequent and determine if the rule is valid.  Decision-procedures are also 
allowed as rules really are functions on Sequents.  Rules of the above form are implemented as 
simulataneous rewrites, where $G$ is the redex, and $S_1, \ldots, S_n$ are the contracta.

In order to get this to work, the rewriter is extended with contexts, which are terms that contain 
holes.  Consider the rule for conjunction elimination:

$$
\begin{array}{l}
H, x\colon A \rightarrow B, J[x] \vdash C[x]\\
{\tt by} x1 x2\\
H, x_1\colon A, x_2\colon B, J[{\tt pair}(x1,x2)] \vdash C[{\tt pair}(x1,x2)]
\end{array}
$$

In this rule, $H$, $J$, and $C$ specify collections of statements. In a rewrite, these variables
specify contexts in which to perform the rewrite.  Using the notation $C[t; x_1, \ldots, x_n]$ for
the context $C$ containing the term $t$, and free variables $x_1, \ldots, x_n$, this rule can be
compiled to the rewrite:

$$ H[x\colon A \rightarrow B, J[C; x]] \leftrightarrow_{x_1, x_2} H[x_1\colon A, x_2\colon B, J[C;
{\tt pair}(x_1,x_2)]]
$$

During the rewrite, the addresses of the context subterms must be specified as parameters to the 
Rule.

\end{document}

% -*-
% Local Variables:
% Mode: LaTeX
% fill-column: 100
% TeX-command-default: "LaTeX/dvips Interactive"
% End:
% -*-
